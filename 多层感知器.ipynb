{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6Kg4WiEuw9XWyHMqcvt3d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mrcold2002/colab_code/blob/main/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E5%99%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#多层感知器\n",
        "\n",
        "## 隐藏层\n",
        "\n",
        "$H=XW_h+b_h$\n",
        "\n",
        "$O=HW_o+b_o$\n",
        "\n",
        "联立得 $O=XW_hW_o+b_hW_o+b_o$,相当于一个单层神经网络权重层$W_hW_o$,$b_hW_o+b_o$,即便添加更多隐含层，多层感知器的设计与仅含输出层的单层神经网络等价\n",
        "\n",
        "上述问题根源是全连接层只对数据做仿射变化，而多个仿射变换的叠加仍是一个仿射变换。解决问题的一个方法是引入非线性变化，例如对隐藏变量使用按元素运算的非线性函数进行变换，然后再作为下一个连接层的输入，这个非线性函数称为激活函数，下面介绍几个常用激活函数\n",
        "\n",
        "## 激活函数\n",
        "\n",
        "1. ReLU函数\n",
        "$ReLU(x)=max(x,0)$\n",
        "2. sigmoid函数\n",
        "$sigmoid(x)=\\frac{1}{1+exp(-x)}$\n",
        "3. tanh函数\n",
        "$tanh(x)=\\frac{1-exp(-2x)}{1+exp(-2x)}$\n",
        "\n",
        "## 多层感知器\n",
        "\n",
        "多层感知器是含有至少一个隐藏层的一个有全连接层组成的神经网络，且每个颖仓曾的输出通过激活函数进行变换。多层感知器的层数和各隐含层中的隐藏单元个数都是超参数。\n",
        "多层感知器按以下方式进行输出$$H=\\phi(XW_h+b_h)$$$$O=HW_o+b_o$$\n",
        "其中$\\phi$表示激活函数。\n",
        "\n",
        "在分类问题中，我们可以对输出O做softmax运算，并用softmax回归中的交叉熵损失函数，\n",
        "在回归问题中，我们将输出层的输出个数设为1，并将输出O直接提供给线性回归中的平方损失函数。\n"
      ],
      "metadata": {
        "id": "i95rL9jn16V5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 多层感知器从零开始实现"
      ],
      "metadata": {
        "id": "U5sJP2Ms5frj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0 导入包和模块\n",
        "%matplotlib inline\n",
        "import d2lzh as d2l\n",
        "from mxnet import nd\n",
        "from mxnet.gluon import loss as gloss,nn"
      ],
      "metadata": {
        "id": "ArueSHYQ5vHL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKE7Apiw0XVX",
        "outputId": "53157813-0466-4fa8-e7c7-319e8fef06e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading /root/.mxnet/datasets/fashion-mnist/train-images-idx3-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-images-idx3-ubyte.gz...\n",
            "Downloading /root/.mxnet/datasets/fashion-mnist/train-labels-idx1-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz...\n",
            "Downloading /root/.mxnet/datasets/fashion-mnist/t10k-images-idx3-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/t10k-images-idx3-ubyte.gz...\n",
            "Downloading /root/.mxnet/datasets/fashion-mnist/t10k-labels-idx1-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/t10k-labels-idx1-ubyte.gz...\n"
          ]
        }
      ],
      "source": [
        "# 1 读取数据集\n",
        "batch_size=256\n",
        "train_iter,test_iter=d2l.load_data_fashion_mnist(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 定义参数模型\n",
        "num_inputs,num_outputs,num_hiddens=784,10,512\n",
        "W1=nd.random.normal(scale=0.01,shape=(num_inputs,num_hiddens))\n",
        "b1=nd.zeros(num_hiddens)\n",
        "W2=nd.random.normal(scale=0.01,shape=(num_hiddens,num_outputs))\n",
        "b2=nd.zeros(num_outputs)\n",
        "params=[W1,b1,W2,b2]\n",
        "\n",
        "for param in params:\n",
        "  param.attach_grad()#标识要获取梯度"
      ],
      "metadata": {
        "id": "fQkhgrmO8zZ5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 定义激活函数\n",
        "def relu(X):\n",
        "  return nd.maximum(X,0)"
      ],
      "metadata": {
        "id": "CUio6J2s-guW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4 定义模型\n",
        "def net(X):\n",
        "  X=X.reshape((-1,num_inputs))\n",
        "  H=relu(nd.dot(X,W1)+b1)\n",
        "  return nd.dot(H,W2)+b2"
      ],
      "metadata": {
        "id": "gcmUM5vNAEIZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5 定义损失函数\n",
        "loss=gloss.SoftmaxCrossEntropyLoss()"
      ],
      "metadata": {
        "id": "A9rk3XrUAGvT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6 训练模型\n",
        "num_epochs,lr=5,0.5\n",
        "d2l.train_ch3(net,train_iter,test_iter,loss,num_epochs,batch_size,params,lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhGdWfoOAGx2",
        "outputId": "3e0818cb-2ab8-4431-8c38-169a8a56ea2d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1, loss 0.8164, train acc 0.699, test acc 0.812\n",
            "epoch 2, loss 0.4903, train acc 0.821, test acc 0.845\n",
            "epoch 3, loss 0.4295, train acc 0.841, test acc 0.858\n",
            "epoch 4, loss 0.3967, train acc 0.854, test acc 0.867\n",
            "epoch 5, loss 0.3682, train acc 0.864, test acc 0.869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "hiddens=256\n",
        "\n",
        "epoch 1, loss 0.8165, train acc 0.690, test acc 0.827\n",
        "\n",
        "epoch 2, loss 0.4939, train acc 0.816, test acc 0.841\n",
        "\n",
        "epoch 3, loss 0.4284, train acc 0.841, test acc 0.852\n",
        "\n",
        "epoch 4, loss 0.3961, train acc 0.854, test acc 0.862\n",
        "\n",
        "epoch 5, loss 0.3725, train acc 0.862, test acc 0.875\n",
        "\n",
        "hiddens=512\n",
        "\n",
        "epoch 1, loss 0.8164, train acc 0.699, test acc 0.812\n",
        "\n",
        "epoch 2, loss 0.4903, train acc 0.821, test acc 0.845\n",
        "\n",
        "epoch 3, loss 0.4295, train acc 0.841, test acc 0.858\n",
        "\n",
        "epoch 4, loss 0.3967, train acc 0.854, test acc 0.867\n",
        "\n",
        "epoch 5, loss 0.3682, train acc 0.864, test acc 0.869\n",
        "\n",
        "并无过大差距"
      ],
      "metadata": {
        "id": "tRJkwHTjBFNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 多层感知器的简洁实现"
      ],
      "metadata": {
        "id": "tJkuSUFYAzl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import d2lzh as d2l\n",
        "from mxnet import gluon,init\n",
        "from mxnet.gluon import loss as gloss,nn"
      ],
      "metadata": {
        "id": "ppe6mW6FCTWu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 定义模型\n",
        "net =nn.Sequential()\n",
        "net.add(nn.Dense(256,activation='relu'),nn.Dense(10))\n",
        "net.initialize(init.Normal(sigma=0.01))"
      ],
      "metadata": {
        "id": "FH-Li_EEAePh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 训练模型\n",
        "batch_size=256\n",
        "train_iter,test_iter=d2l.load_data_fashion_mnist(batch_size)\n",
        "loss=gloss.SoftmaxCrossEntropyLoss()\n",
        "trainer=gluon.Trainer(net.collect_params(),'sgd',{'learning_rate':0.5})\n",
        "num_epochs=5\n",
        "d2l.train_ch3(net,train_iter,test_iter,loss,num_epochs,batch_size,None,None,trainer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geD1bzgFCwLX",
        "outputId": "c1a88ecc-3c47-4d15-d034-bb341e03dc61"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1, loss 0.3533, train acc 0.869, test acc 0.856\n",
            "epoch 2, loss 0.3390, train acc 0.875, test acc 0.881\n",
            "epoch 3, loss 0.3270, train acc 0.880, test acc 0.883\n",
            "epoch 4, loss 0.3156, train acc 0.884, test acc 0.887\n",
            "epoch 5, loss 0.3063, train acc 0.886, test acc 0.884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SFQJJAYADPsP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}